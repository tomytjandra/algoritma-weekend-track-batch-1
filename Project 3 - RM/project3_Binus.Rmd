---
title: "Algoritma Academy: Team BINUS University"
author: "Even Yosua,  Handoyo Sjarif, Ridan Lukita, Tomy Tjandra"
date: "May 19, 2018"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: 
        collapsed: false
    theme: flatly
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Import Library
Hello this our 3rd project, in this project we try to build regression analysis report that applied what we have learn in workshop. 
First we import the library that we use in this project
```{r message=FALSE}
library(dplyr)
library(car)
```

#Data Preparation
Next, we import our data set. We use this data set to finds on the different socioeconomic variables most highly correlated to crime rates. To make it easier we rename our data frame to make it readable. 
```{r}
crime <- read.csv("data_input/crime.csv") %>% 
  dplyr::select(-X)

names(crime) <- c("percent_m", "is_south", "mean_education", "police_exp60", "police_exp59", "labour_participation", "m_per1000f", "state_pop", "nonwhites_per1000", "unemploy_m24", "unemploy_m39", "gdp", "inequality", "prob_prison", "time_prison", "crime_rate")
```

#Step-wise Regression {.tabset}
In this step, we make a step-wise regression. We use all of direction(forward, backward, both) to find which one is the best direction.

##Backward
```{r}
lm.all <- lm(crime_rate ~., crime)
crime.backward <- step(lm.all, direction="backward")
crime.backward$call
```

```{r}
crime.backward.olm <- lm(formula = crime_rate ~ percent_m + mean_education + police_exp60 + m_per1000f + unemploy_m24 + unemploy_m39 + inequality + prob_prison, data = crime)

summary(crime.backward.olm)
```

at this result, we get 8 indenpendent variables with 0,7444 Adjusted R-squared. 

##Forward
```{r}
lm.none <- lm(crime_rate ~ 1, crime)
crime.forward <- step(lm.none, scope=list(lower=lm.none, upper=lm.all), direction="forward")
crime.forward$call
```
```{r}
crime.forward.olm <- lm(formula = crime_rate ~ police_exp60 + inequality + mean_education + percent_m + prob_prison + unemploy_m39, data = crime)

summary(crime.forward.olm)
```

at this result, we get 6 indenpendent variables with 0,7307 Adjusted R-squared. 

##Both
```{r}
crime.both <- step(lm.none, scope = list(upper=lm.all), data=crime, direction="both")
crime.both$call
```
```{r}
crime.both.olm <- lm(formula = crime_rate ~ police_exp60 + inequality + mean_education + percent_m + prob_prison + unemploy_m39, data = crime)

summary(crime.both.olm)
```

at this result, we get 6 indenpendent variables with 0,7307 Adjusted R-squared.

#Predicting Crime Rate
With previews result, we decided to use backward step-wise regression, because it have higher Adjusted R-squared value. Even the backward have more independent variables than forward and both, backward have 1% Adjusted R-squared differences.

Next,  we predict crime rates, using maximum values from each coloumn of the independent variables. 
```{r}
crime.max.data <- data.frame(max(crime$percent_m), max(crime$mean_education), max(crime$police_exp60), max(crime$m_per1000f), max(crime$unemploy_m24), max(crime$unemploy_m39), max(crime$inequality), max(crime$prob_prison))

names(crime.max.data) <- c("percent_m", "mean_education", "police_exp60", "m_per1000f", "unemploy_m24", "unemploy_m39", "inequality", "prob_prison")

predict(crime.backward.olm, crime.max.data)
```
So with our model we can predict that there is 2980 incident happens if we used maximum values from each coloumn of the independent variables. 

#Check Homoskedasticity
Next, we try to check homoskedasticity of our model. 
```{r}
plot(crime$crime_rate,
  residuals(crime.backward.olm), ylab="Residuals", xlab="Crime Rate")
abline(h = 0, col="goldenrod4", lwd=2)
```

So from that result, we can conclude that we can use that model for this data set. 

#Check Multicolinearity
Lastly we try to check the dependencies between indenpendent variables. 
```{r}
vif(crime.backward.olm)
```

From that result we can tolerant dependencies between our indenpendent variables because values is between 0-5. 

### No Pain No Gain ~
Good Bye and See You Again
